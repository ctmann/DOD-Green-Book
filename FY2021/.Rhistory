geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(lables = scales::dollar)
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels= scales::dollar)
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels= scales::dollar)+
scale_x_continuous(date_breaks = "1 year",
date_labels = "%Y")
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels= scales::dollar)+
scale_x_continuous(date_breaks = "1 year",
date_labels = "%Y")
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels = scales::dollar) +
scale_x_date(date_breaks = "1 year", date_labels = "%Y")
?scale_x_date
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels = scales::dollar) +
scale_x_date(date_breaks = "1 year",
date_labels = "%Y")
alcohol_sales_tbl %>%
ggplot(aes(x = date, y = price)) +
geom_line(size = 1,
color = palette_light()[[1]] ) +
geom_smooth(method="loess")+
labs(title = "US Alcohol Sales: Monthly",
x = "",
y = "Millions")+
scale_y_continuous(labels = scales::dollar) +
scale_x_date(date_breaks = "1 year",
date_labels = "%Y")
?tk_ts
alcohol_sales_ts
alcohol_sales_ts <- tk_ts(alcohol_sales_tbl, start = 2007, freq = 12, silent = TRUE)
alcohol_sales_ts
has_timetk_idx(alcohol_sales_ts)
fit_ets <- alcohol_sales_ts %>%
ets()
fit_ets
?ets
fit_ets
sw_tidy(fit_ets)
sw_glance(fit_ets)
sw_augment(fit_ets)
sw_augment(fit_ets) %>%
ggplot(aes(x = index,
y = .resid) )+
geom_hline(yintercept=0,
color = "grey40")
scale_x_yearmon(n = 10)
sw_augment(fit_ets) %>%
ggplot(aes(x = index,
y = .resid) )+
geom_hline(yintercept=0,
color = "grey40")+
geom_point(color = palette_light()[[1]],
alpha = .5) +
scale_x_yearmon(n = 10)
sw_augment(fit_ets) %>%
ggplot(aes(x = index,
y = .resid) )+
geom_hline(yintercept=0,
color = "grey40")+
geom_point(color = palette_light()[[1]],
alpha = .5) +
scale_x_yearmon(n = 10)+
geom_smooth(method = "loess")
sw_augment(fit_ets) %>%
ggplot(aes(x = index,
y = .resid) )+
geom_hline(yintercept=0,
color = "grey40")+
geom_point(color = palette_light()[[1]],
alpha = .5) +
scale_x_yearmon(n = 10)+
geom_smooth(method = "loess")+
scale_x_yearmon(n = 10)
?scale_x_yearmon
sw_augment(fit_ets) %>%
ggplot(aes(x = index,
y = .resid) )+
geom_hline(yintercept=0,
color = "grey40")+
geom_point(color = palette_light()[[1]],
alpha = .5) +
scale_x_yearmon(n = 10)+
geom_smooth(method = "loess")+
scale_x_yearmon(n = 10)
augment_fit_ets %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
augment_fit_ets %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
sw_augment(fit_ets)
augment_fit_ets %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
augment_fit_ets <- sw_tidy(fit_ets)
sw_glance(fit_ets)
sw_augment(fit_ets)
augment_fit_ets %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
augment_fit_ets
augment_fit_ets
augment_fit_ets %>%
ggplot(aes(x = index, y = .resid))
augment_fit_ets
sw_tidy(fit_ets)
sw_augment(fit_ets)
sw_augment(fit_ets) %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
sw_augment(fit_ets) %>%
ggplot(aes(x = index, y = .resid)) +
geom_hline(yintercept = 0, color = "grey40") +
geom_point(color = palette_light()[[1]], alpha = 0.5) +
geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
decomp_fit_ets <- sw_tidy_decomp(fit_ets)
decomp_fit_ets
library(idyverse)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
.libpaths()
.libpaths()
library(acepack)
library(alphavantager)
library(arsenal)
library(askpass)
library(assertthat)
library(backports)
library(base64enc)
library(BH)
library(bindr)
library(bindrcpp)
library(binom)
install.packages(c("backports", "bit", "blob", "callr", "checkmate", "chron", "classInt", "cluster", "covr", "curl", "data.table", "devtools", "digest", "dplyr", "e1071", "ellipsis", "fansi", "farver", "feather", "foreign", "fracdiff", "fs", "geosphere", "git2r", "glue", "haven", "hexbin", "hms", "htmltools", "httpuv", "igraph", "isoband", "jsonlite", "kernlab", "KernSmooth", "later", "lattice", "lmtest", "maptools", "markdown", "MASS", "Matrix", "mclust", "memisc", "mgcv", "mime", "mnormt", "network", "nlme", "nloptr", "nnet", "openssl", "padr", "pdftools", "pkgbuild", "plyr", "processx", "promises", "proxyC", "ps", "purrr", "quadprog", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "reticulate", "rgeos", "rJava", "rlang", "robustbase", "roxygen2", "rpart", "RSpectra", "RSQLite", "Rttf2pt1", "scales", "sf", "sna", "sp", "spacyr", "stringdist", "stringi", "survival", "sys", "testthat", "tibble", "tidyr", "tidyselect", "tseries", "TTR", "units", "urltools", "usethis", "uuid", "vctrs", "xlsx", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages("tidyverse")
library(tidyverse)
install.packages("Rcpp")
library(Rcpp)
library(tidyverse)
# Download Function -----------------------------------------------------------
#' # Import  Data ------------------------------------------------------------
x <- "http://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 6/"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- "./Data/Raw/FY_2021_Green_Book/FY21 PB Green Book Chap 6/"
?gather
#' Table 6.19-6.21 DOD BA By by Service and Title
#'
#'
#' Download raw files to temp folder locally for processing
#' Raw files stored in subfolder are not necessary
#'
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(readxl)
library(stringr)
nettle_clean <- function(location.of.file, my.table.number, dod.service){
# Due to missing column names, read_excel requires col_names = False
orig <-  read_excel(location.of.file,
na = "0", skip = 4, col_names = FALSE)
# Basic Shaping (remove blank cols)
orig <- orig %>%
select(-2,-3)
# Easy to create Universal Col Header
n <-  1948:2025
my.col.header <- c("Public Law Title", n, "deflator.type")
# Remove trailing dots (and footnotes) from first col
orig[,1] <- str_trim(str_replace_all(orig[,1], "[0-9.]+", ""))
## End orig
## Begin current
current <- orig %>%
slice(1:10) %>% #< This assumes no more accounts will be added. In FY2020, one was.
slice(-1) %>%
mutate(delator.type = "Current")
# Rename Col Headers
names(current) <- my.col.header
##< End Current>
### Begin Constant
constant  <- orig %>%
slice(12:20) %>% #< This assumes no more accounts will be added. In FY2020, one was.
mutate(delator.type = "Constant")
# Rename Col Headers
names(constant) <- my.col.header
##<End Constant
# Combine Current and Constant Datasets
combined <- bind_rows(constant, current)
# Tidy -----------------------------------------------------------------
tidied <- combined %>%
gather(FY, Amount, -`Public Law Title`,-deflator.type)
# Format Fixing ------------------------------------------------------------------
# Convert String to Millions
tidied$Amount <- as.numeric(tidied$Amount)
tidied$Amount <- tidied$Amount *1e6
# Replace NAs with 0
tidied <- tidied %>%
replace_na(list(Amount = 0))
# Meta --------------------------------------------------------------
# Add Source Notes
tidied$data.notes <- "All enacted war and supplemental funding is included; Includes both discretionary and mandatory "
tidied$source.table <- my.table.number
tidied$Service <- my.dod.service
return(tidied)
}
# tidy --------------------------------------------------------------------
#' Table 6.19-6.21 DOD BA By by Service and Title
#'
#'
#' Download raw files to temp folder locally for processing
#' Raw files stored in subfolder are not necessary
#'
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(readxl)
library(stringr)
# Create download Function -----------------------------------------------------------
#' # Import  Data ------------------------------------------------------------
x <- "http://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 6/"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- "./Data/Raw/FY_2021_Green_Book/FY21 PB Green Book Chap 6/"
# Create Clean Function ----------------------------------------------------------
nettle_clean <- function(location.of.file, my.table.number, dod.service){
# Due to missing column names, read_excel requires col_names = False
orig <-  read_excel(location.of.file,
na = "0", skip = 4, col_names = FALSE)
# Basic Shaping (remove blank cols)
orig <- orig %>%
select(-2,-3)
# Easy to create Universal Col Header
n <-  1948:2025
my.col.header <- c("Public Law Title", n, "deflator.type")
# Remove trailing dots (and footnotes) from first col
orig[,1] <- str_trim(str_replace_all(orig[,1], "[0-9.]+", ""))
## End orig
## Begin current
current <- orig %>%
slice(1:10) %>% #< This assumes no more accounts will be added. In FY2020, one was.
slice(-1) %>%
mutate(delator.type = "Current")
# Rename Col Headers
names(current) <- my.col.header
##< End Current>
### Begin Constant
constant  <- orig %>%
slice(12:20) %>% #< This assumes no more accounts will be added. In FY2020, one was.
mutate(delator.type = "Constant")
# Rename Col Headers
names(constant) <- my.col.header
##<End Constant
# Combine Current and Constant Datasets
combined <- bind_rows(constant, current)
# Tidy -----------------------------------------------------------------
tidied <- combined %>%
gather(FY, Amount, -`Public Law Title`,-deflator.type)
# Format Fixing ------------------------------------------------------------------
# Convert String to Millions
tidied$Amount <- as.numeric(tidied$Amount)
tidied$Amount <- tidied$Amount *1e6
# Replace NAs with 0
tidied <- tidied %>%
replace_na(list(Amount = 0))
# Meta --------------------------------------------------------------
# Add Source Notes
tidied$data.notes <- "All enacted war and supplemental funding is included; Includes both discretionary and mandatory "
tidied$source.table <- my.table.number
tidied$Service <- my.dod.service
return(tidied)
}
# Use  -----------------------------------------------------------------
# Download the file with nettle function (Assume Identical Shape of Separate Tabs)
#   nettle_clean requires four inputs
#   the last two are for print purposes
#   Inputs: zip.url, spreadsheet.name, my.table.number, dod.service
# Download 6-19
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-19.xlsx")
my.table.number <- "tbl.6-19"
my.dod.service <- "Army"
army <- nettle_clean(location.of.file = location.of.file,
my.table.number,
my.dod.service)
# Download 6-20
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-20.xlsx")
my.table.number <- "tbl.6-20"
my.dod.service <- "Navy"
navy <- nettle_clean(location.of.file = location.of.file, my.table.number, my.dod.service)
# Download 6-21
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-21.xlsx")
my.table.number <- "tbl.6-21"
my.dod.service <- "Air.Force"
air.force <- nettle_clean(location.of.file = location.of.file, my.table.number, my.dod.service)
# tidy --------------------------------------------------------------------
setwd("~/Documents/R Programming/Repositories/DOD-Green-Book/FY2021")
#' Table 6.19-6.21 DOD BA By by Service and Title
#'
#'
#' Download raw files to temp folder locally for processing
#' Raw files stored in subfolder are not necessary
#'
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(readxl)
library(stringr)
# Create download Function -----------------------------------------------------------
#' # Import  Data ------------------------------------------------------------
x <- "http://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 6/"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- "./Data/Raw/FY_2021_Green_Book/FY21 PB Green Book Chap 6/"
# Create Clean Function ----------------------------------------------------------
nettle_clean <- function(location.of.file, my.table.number, dod.service){
# Due to missing column names, read_excel requires col_names = False
orig <-  read_excel(location.of.file,
na = "0", skip = 4, col_names = FALSE)
# Basic Shaping (remove blank cols)
orig <- orig %>%
select(-2,-3)
# Easy to create Universal Col Header
n <-  1948:2025
my.col.header <- c("Public Law Title", n, "deflator.type")
# Remove trailing dots (and footnotes) from first col
orig[,1] <- str_trim(str_replace_all(orig[,1], "[0-9.]+", ""))
## End orig
## Begin current
current <- orig %>%
slice(1:10) %>% #< This assumes no more accounts will be added. In FY2020, one was.
slice(-1) %>%
mutate(delator.type = "Current")
# Rename Col Headers
names(current) <- my.col.header
##< End Current>
### Begin Constant
constant  <- orig %>%
slice(12:20) %>% #< This assumes no more accounts will be added. In FY2020, one was.
mutate(delator.type = "Constant")
# Rename Col Headers
names(constant) <- my.col.header
##<End Constant
# Combine Current and Constant Datasets
combined <- bind_rows(constant, current)
# Tidy -----------------------------------------------------------------
tidied <- combined %>%
gather(FY, Amount, -`Public Law Title`,-deflator.type)
# Format Fixing ------------------------------------------------------------------
# Convert String to Millions
tidied$Amount <- as.numeric(tidied$Amount)
tidied$Amount <- tidied$Amount *1e6
# Replace NAs with 0
tidied <- tidied %>%
replace_na(list(Amount = 0))
# Meta --------------------------------------------------------------
# Add Source Notes
tidied$data.notes <- "All enacted war and supplemental funding is included; Includes both discretionary and mandatory "
tidied$source.table <- my.table.number
tidied$Service <- my.dod.service
return(tidied)
}
# Use  -----------------------------------------------------------------
# Download the file with nettle function (Assume Identical Shape of Separate Tabs)
#   nettle_clean requires four inputs
#   the last two are for print purposes
#   Inputs: zip.url, spreadsheet.name, my.table.number, dod.service
# Download 6-19
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-19.xlsx")
my.table.number <- "tbl.6-19"
my.dod.service <- "Army"
army <- nettle_clean(location.of.file = location.of.file,
my.table.number,
my.dod.service)
# Download 6-20
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-20.xlsx")
my.table.number <- "tbl.6-20"
my.dod.service <- "Navy"
navy <- nettle_clean(location.of.file = location.of.file, my.table.number, my.dod.service)
# Download 6-21
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-21.xlsx")
my.table.number <- "tbl.6-21"
my.dod.service <- "Air.Force"
air.force <- nettle_clean(location.of.file = location.of.file, my.table.number, my.dod.service)
# tidy --------------------------------------------------------------------
location.of.file
# Download 6-19
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-19.xlsx")
my.table.number <- "tbl.6-19"
my.dod.service <- "Army"
army <- nettle_clean(location.of.file = location.of.file,
my.table.number,
my.dod.service)
army
orig <-  read_excel(location.of.file,
na = "0", skip = 4, col_names = FALSE)
orig
#' Table 6.19-6.21 DOD BA By by Service and Title
#'
#'
#' Download raw files to temp folder locally for processing
#' Raw files stored in subfolder are not necessary
#'
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(readxl)
library(stringr)
# Create download Function -----------------------------------------------------------
#' # Import  Data ------------------------------------------------------------
x <- "http://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 6/"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- "./Data/Raw/FY_2021_Green_Book/FY21 PB Green Book Chap 6/"
# Create Clean Function ----------------------------------------------------------
location.of.file <- paste0(my.filename,"FY21 PB Green Book Table 6-19.xlsx")
my.table.number <- "tbl.6-19"
my.dod.service <- "Army"
read_excel(location.of.file,
na = "0", skip = 4, col_names = FALSE)
