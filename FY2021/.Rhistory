geom_smooth(method = "loess") +
scale_x_yearmon(n = 10) +
labs(title = "US Alcohol Sales: ETS Residuals", x = "") +
theme_tq()
decomp_fit_ets <- sw_tidy_decomp(fit_ets)
decomp_fit_ets
library(idyverse)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
.libpaths()
.libpaths()
library(acepack)
library(alphavantager)
library(arsenal)
library(askpass)
library(assertthat)
library(backports)
library(base64enc)
library(BH)
library(bindr)
library(bindrcpp)
library(binom)
install.packages(c("backports", "bit", "blob", "callr", "checkmate", "chron", "classInt", "cluster", "covr", "curl", "data.table", "devtools", "digest", "dplyr", "e1071", "ellipsis", "fansi", "farver", "feather", "foreign", "fracdiff", "fs", "geosphere", "git2r", "glue", "haven", "hexbin", "hms", "htmltools", "httpuv", "igraph", "isoband", "jsonlite", "kernlab", "KernSmooth", "later", "lattice", "lmtest", "maptools", "markdown", "MASS", "Matrix", "mclust", "memisc", "mgcv", "mime", "mnormt", "network", "nlme", "nloptr", "nnet", "openssl", "padr", "pdftools", "pkgbuild", "plyr", "processx", "promises", "proxyC", "ps", "purrr", "quadprog", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "RCurl", "reticulate", "rgeos", "rJava", "rlang", "robustbase", "roxygen2", "rpart", "RSpectra", "RSQLite", "Rttf2pt1", "scales", "sf", "sna", "sp", "spacyr", "stringdist", "stringi", "survival", "sys", "testthat", "tibble", "tidyr", "tidyselect", "tseries", "TTR", "units", "urltools", "usethis", "uuid", "vctrs", "xlsx", "XML", "xml2", "xts", "yaml", "zoo"))
install.packages("tidyverse")
library(tidyverse)
install.packages("Rcpp")
library(Rcpp)
library(tidyverse)
library(tidyr)
library(dplyr)
library(readxl)
library(stringr)
library(readr)
library(readxl)
library(zoo)
# Preliminaries -----------------------------------------------------------
# Set working dir manually
# Download new raw data?
download.switch <- "download.switch.on"
download.switch <- "download.switch.off"
# Import  Data from Website------------------------------------------------------------
x <- "https://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 2.xlsx"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- nettle_downzip(x,y)
#excel_sheets(my.filename)
# Reshape -----------------------------------------------------------------
#Import  There are 18 sheet
t <-  lapply(excel_sheets(my.filename)[1:18],
read_excel,
path = my.filename,
col_names = F,
skip = 5 )
str_split
separate
?separate
?str_split
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
x
y
tidy_grnbook_supps_table <- function(t){
# Deprecated: Remove 5 rows at top of each sheet using read_excel 'skip' argument
# t <- (t[-1:-5,])
#t <- t[[1]]
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
# Set all Colnames and remove extra row (there ought to be a function that does this)
colnames(t) <- t[1,]
t <- t[-1,]
# Make all colnames r-friendly
colnames(t) <- make.names(colnames(t))
# Select (don't omit!) Columns to use
t <- t[, c(1:3, 5:11)]
# Forward Fill for first two columns (Military Dept, and FY)
t[1,2] <- t[2,2] #< Modified in FY2020 ***
t[,c(1:2)] <- na.locf(t[,c('Military.Department', 'FY')])
# DANGER! Remove rows that contain a NA in the Public Law Title column
t <- t[complete.cases(t$Account),]
# Remove non-alphabetic characters from Public.Law.Title column numbers and periods
t$Account <- str_trim(gsub("[0-9.]+", "", t$Account))
# Remove 'continued' from Military Department
t$Military.Department <- str_trim(gsub("(Continued)", "", t$Military.Department, fixed = "True"))
# Convert relevant cols to numeric
t$FY <- as.numeric(gsub("FY ", "", t$FY))
# Gather and Tidy
t <- gather(t, Public.Law.Title, Amount, c(-1:-3))
# Convert Amount to numeric
t$Amount <- as.numeric(t$Amount)
# There are NAs and 0 values mingled in Amount column. Change them all to 0
t[is.na(t)] <- 0
# This dataset was originally adjusted to be "in millions." Mulitply for unadjusted amount
t$Amount <- t$Amount * 1e6
##### PreCalculated Totals ####
#' The original dataset contains hard-coded totals which do not match real calculated totals
#' should be removed but can be useful for checking the accuracy of this script:
# Remove precalculated totals but save the subset for future use
# Save Totals Subset - This doesn't seem to work outside of the function
#precalculated_totals <- t %>%
# filter(grepl("total", t$Military.Department, ignore.case = T))
# Remove  published "Totals" Column
# Note: Published totals are consistently $1-2 million off from caluclated totals
# For more info, see checksums script
t <- t %>%
filter(!grepl("total", t$Military.Department, ignore.case = T))
return(t)
}
# Tidy data new function -------------------------------------------------
t <- lapply(X = t, FUN = tidy_grnbook_supps_table)
t <- do.call(rbind, t)
# Note: this could be done with purr's map, as well
t
tidy_grnbook_supps_table <- function(t){
# Deprecated: Remove 5 rows at top of each sheet using read_excel 'skip' argument
# t <- (t[-1:-5,])
#t <- t[[1]]
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
# Set all Colnames and remove extra row (there ought to be a function that does this)
colnames(t) <- t[1,]
t <- t[-1,]
# Make all colnames r-friendly
colnames(t) <- make.names(colnames(t))
# Select (don't omit!) Columns to use
t <- t[, c(1:3, 5:11)]
# Forward Fill for first two columns (Military Dept, and FY)
t[1,2] <- t[2,2] #< Modified in FY2020 ***
t[,c(1:2)] <- na.locf(t[,c('Military.Department', 'FY')])
# DANGER! Remove rows that contain a NA in the Public Law Title column
t <- t[complete.cases(t$Account),]
# Remove non-alphabetic characters from Public.Law.Title column numbers and periods
t$footnote <- str_extract("[0-9.] +", t$Account)
t$Account <- str_trim(gsub("[0-9.]+", "", t$Account))
# Remove 'continued' from Military Department
t$Military.Department <- str_trim(gsub("(Continued)", "", t$Military.Department, fixed = "True"))
# Convert relevant cols to numeric
t$FY <- as.numeric(gsub("FY ", "", t$FY))
# Gather and Tidy
t <- gather(t, Public.Law.Title, Amount, c(-1:-3))
# Convert Amount to numeric
t$Amount <- as.numeric(t$Amount)
# There are NAs and 0 values mingled in Amount column. Change them all to 0
t[is.na(t)] <- 0
# This dataset was originally adjusted to be "in millions." Mulitply for unadjusted amount
t$Amount <- t$Amount * 1e6
##### PreCalculated Totals ####
#' The original dataset contains hard-coded totals which do not match real calculated totals
#' should be removed but can be useful for checking the accuracy of this script:
# Remove precalculated totals but save the subset for future use
# Save Totals Subset - This doesn't seem to work outside of the function
#precalculated_totals <- t %>%
# filter(grepl("total", t$Military.Department, ignore.case = T))
# Remove  published "Totals" Column
# Note: Published totals are consistently $1-2 million off from caluclated totals
# For more info, see checksums script
t <- t %>%
filter(!grepl("total", t$Military.Department, ignore.case = T))
return(t)
}
# Tidy data new function -------------------------------------------------
t <- lapply(X = t, FUN = tidy_grnbook_supps_table)
t <- do.call(rbind, t)
# Note: this could be done with purr's map, as well
tidy_grnbook_supps_table <- function(t){
# Deprecated: Remove 5 rows at top of each sheet using read_excel 'skip' argument
# t <- (t[-1:-5,])
#t <- t[[1]]
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
# Set all Colnames and remove extra row (there ought to be a function that does this)
colnames(t) <- t[1,]
t <- t[-1,]
# Make all colnames r-friendly
colnames(t) <- make.names(colnames(t))
# Select (don't omit!) Columns to use
t <- t[, c(1:3, 5:11)]
# Forward Fill for first two columns (Military Dept, and FY)
t[1,2] <- t[2,2] #< Modified in FY2020 ***
t[,c(1:2)] <- na.locf(t[,c('Military.Department', 'FY')])
# DANGER! Remove rows that contain a NA in the Public Law Title column
t <- t[complete.cases(t$Account),]
# Remove non-alphabetic characters from Public.Law.Title column numbers and periods
#t$footnote <- str_extract("[0-9.] +", t$Account)
t$Account <- str_trim(gsub("[0-9.]+", "", t$Account))
# Remove 'continued' from Military Department
t$Military.Department <- str_trim(gsub("(Continued)", "", t$Military.Department, fixed = "True"))
# Convert relevant cols to numeric
t$FY <- as.numeric(gsub("FY ", "", t$FY))
# Gather and Tidy
t <- gather(t, Public.Law.Title, Amount, c(-1:-3))
# Convert Amount to numeric
t$Amount <- as.numeric(t$Amount)
# There are NAs and 0 values mingled in Amount column. Change them all to 0
t[is.na(t)] <- 0
# This dataset was originally adjusted to be "in millions." Mulitply for unadjusted amount
t$Amount <- t$Amount * 1e6
##### PreCalculated Totals ####
#' The original dataset contains hard-coded totals which do not match real calculated totals
#' should be removed but can be useful for checking the accuracy of this script:
# Remove precalculated totals but save the subset for future use
# Save Totals Subset - This doesn't seem to work outside of the function
#precalculated_totals <- t %>%
# filter(grepl("total", t$Military.Department, ignore.case = T))
# Remove  published "Totals" Column
# Note: Published totals are consistently $1-2 million off from caluclated totals
# For more info, see checksums script
t <- t %>%
filter(!grepl("total", t$Military.Department, ignore.case = T))
return(t)
}
# Tidy data new function -------------------------------------------------
t <- lapply(X = t, FUN = tidy_grnbook_supps_table)
t <- do.call(rbind, t)
# Note: this could be done with purr's map, as well
tidy_grnbook_supps_table <- function(t){
# Deprecated: Remove 5 rows at top of each sheet using read_excel 'skip' argument
# t <- (t[-1:-5,])
#t <- t[[1]]
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
# Set all Colnames and remove extra row (there ought to be a function that does this)
colnames(t) <- t[1,]
t <- t[-1,]
# Make all colnames r-friendly
colnames(t) <- make.names(colnames(t))
# Select (don't omit!) Columns to use
t <- t[, c(1:3, 5:11)]
# Forward Fill for first two columns (Military Dept, and FY)
t[1,2] <- t[2,2] #< Modified in FY2020 ***
t[,c(1:2)] <- na.locf(t[,c('Military.Department', 'FY')])
# DANGER! Remove rows that contain a NA in the Public Law Title column
t <- t[complete.cases(t$Account),]
# Remove non-alphabetic characters from Public.Law.Title column numbers and periods
#t$footnote <- str_extract("[0-9.] +", t$Account)
t$Account <- str_trim(gsub("[0-9.]+", "", t$Account))
# Remove 'continued' from Military Department
t$Military.Department <- str_trim(gsub("(Continued)", "", t$Military.Department, fixed = "True"))
# Convert relevant cols to numeric
t$FY <- as.numeric(gsub("FY ", "", t$FY))
# Gather and Tidy
t <- gather(t, Public.Law.Title, Amount, c(-1:-3))
# Convert Amount to numeric
t$Amount <- as.numeric(t$Amount)
# There are NAs and 0 values mingled in Amount column. Change them all to 0
t[is.na(t)] <- 0
# This dataset was originally adjusted to be "in millions." Mulitply for unadjusted amount
t$Amount <- t$Amount * 1e6
##### PreCalculated Totals ####
#' The original dataset contains hard-coded totals which do not match real calculated totals
#' should be removed but can be useful for checking the accuracy of this script:
# Remove precalculated totals but save the subset for future use
# Save Totals Subset - This doesn't seem to work outside of the function
#precalculated_totals <- t %>%
# filter(grepl("total", t$Military.Department, ignore.case = T))
# Remove  published "Totals" Column
# Note: Published totals are consistently $1-2 million off from caluclated totals
# For more info, see checksums script
t <- t %>%
filter(!grepl("total", t$Military.Department, ignore.case = T))
return(t)
}
# Tidy data new function -------------------------------------------------
t <- lapply(X = t, FUN = tidy_grnbook_supps_table)
t <- do.call(rbind, t)
# Note: this could be done with purr's map, as well
#' Original DoD Comptroller zip file downloaded here:
#' http://comptroller.defense.gov/BudgetMaterials.aspx
#'
#' Table 2.1 Base Budget, War Funding and Supplementals by Military Department, by P.L. Title
#' (Discretionary Budget Authority)
#'
#' Updated: 05-01-2020 fo FY2021
#'
# Libraries ---------------------------------------------------------------
library(tidyr)
library(dplyr)
library(readxl)
library(stringr)
library(readr)
library(readxl)
library(zoo)
# Preliminaries -----------------------------------------------------------
# Set working dir manually
# Download new raw data?
download.switch <- "download.switch.on"
download.switch <- "download.switch.off"
# Import  Data from Website------------------------------------------------------------
x <- "https://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 2.xlsx"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- nettle_downzip(x,y)
#excel_sheets(my.filename)
# Reshape -----------------------------------------------------------------
#Import  There are 18 sheet
t <-  lapply(excel_sheets(my.filename)[1:18],
read_excel,
path = my.filename,
col_names = F,
skip = 5 )
#' User Defined Cleaning Function ---------------------------------------------------
#' Purpose:Create function that cleans and tidies
#' Note: Rather than removing cols, SELECT them by colname. Sometimes, one sheet will
#' have extra blank cols not included on others that widens orlengthens the array.
tidy_grnbook_supps_table <- function(t){
# Deprecated: Remove 5 rows at top of each sheet using read_excel 'skip' argument
# t <- (t[-1:-5,])
#t <- t[[1]]
# Create Missing Colnames
t[1, 1:3] <- c("Military.Department", "FY", "Account")
# Set all Colnames and remove extra row (there ought to be a function that does this)
colnames(t) <- t[1,]
t <- t[-1,]
# Make all colnames r-friendly
colnames(t) <- make.names(colnames(t))
# Select (don't omit!) Columns to use
t <- t[, c(1:3, 5:11)]
# Forward Fill for first two columns (Military Dept, and FY)
t[1,2] <- t[2,2] #< Modified in FY2020 ***
t[,c(1:2)] <- na.locf(t[,c('Military.Department', 'FY')])
# DANGER! Remove rows that contain a NA in the Public Law Title column
t <- t[complete.cases(t$Account),]
# Remove non-alphabetic characters from Public.Law.Title column numbers and periods
#t$footnote <- str_extract("[0-9.] +", t$Account)
t$Account <- str_trim(gsub("[0-9.]+", "", t$Account))
# Remove 'continued' from Military Department
t$Military.Department <- str_trim(gsub("(Continued)", "", t$Military.Department, fixed = "True"))
# Convert relevant cols to numeric
t$FY <- as.numeric(gsub("FY ", "", t$FY))
# Gather and Tidy
t <- gather(t, Public.Law.Title, Amount, c(-1:-3))
# Convert Amount to numeric
t$Amount <- as.numeric(t$Amount)
# There are NAs and 0 values mingled in Amount column. Change them all to 0
t[is.na(t)] <- 0
# This dataset was originally adjusted to be "in millions." Mulitply for unadjusted amount
t$Amount <- t$Amount * 1e6
##### PreCalculated Totals ####
#' The original dataset contains hard-coded totals which do not match real calculated totals
#' should be removed but can be useful for checking the accuracy of this script:
# Remove precalculated totals but save the subset for future use
# Save Totals Subset - This doesn't seem to work outside of the function
#precalculated_totals <- t %>%
# filter(grepl("total", t$Military.Department, ignore.case = T))
# Remove  published "Totals" Column
# Note: Published totals are consistently $1-2 million off from caluclated totals
# For more info, see checksums script
t <- t %>%
filter(!grepl("total", t$Military.Department, ignore.case = T))
return(t)
}
t <- lapply(X = t, FUN = tidy_grnbook_supps_table)
t <- do.call(rbind, t)
t
names(t)
#' Original DoD Comptroller zip file downloaded here:
#' http://comptroller.defense.gov/BudgetMaterials.aspx
#'
#' Table 2.1 Base Budget, War Funding and Supplementals by Military Department, by P.L. Title
#' (Discretionary Budget Authority)
#'
#' Updated: 05-01-2020 fo FY2021
#'
# Libraries ---------------------------------------------------------------
library(tidyr)
library(dplyr)
library(readxl)
library(stringr)
library(readr)
library(readxl)
library(zoo)
# Preliminaries -----------------------------------------------------------
# Set working dir manually
# Download new raw data?
download.switch <- "download.switch.on"
download.switch <- "download.switch.off"
# Import  Data from Website------------------------------------------------------------
x <- "https://comptroller.defense.gov/Portals/45/Documents/defbudget/fy2021/FY_2021_Green_Book.zip"
y <- "FY21 PB Green Book Chap 2.xlsx"
nettle_downzip <- function(zip.url, zip.file){
my.temporary.zipped.file <- tempfile()   # Zip file will go in here
my.temporarary.zipped.folder <- tempdir() # Unzipped file will go in here
download.file(zip.url, dest = my.temporary.zipped.file) # Download Source Data to Temp file
unzip(my.temporary.zipped.file, exdir = my.temporarary.zipped.folder) # Unzip to Temp directory
location.of.unzipped.file <- paste0(my.temporarary.zipped.folder,"/", zip.file)
return(location.of.unzipped.file )
}
my.filename <- nettle_downzip(x,y)
#excel_sheets(my.filename)
# Reshape -----------------------------------------------------------------
#Import  There are 18 sheet
t <-  lapply(excel_sheets(my.filename)[1:18],
read_excel,
path = my.filename,
col_names = F,
skip = 5 )
t
t[1]
t[[1]] %>% View()
t[[5]] %>% View()
#' Chapter 7:
# Info --------------------------------------------------------------------
#'
#' 7.6 U.S. labor force
#'
#' TOTALS COLUMNS
#'   Total DOD Employment = Active Duty military + DOD Civilian Direct Hires
#'
#'   Total Federal Civilian Employment = DOD Civilian Direct Hires +
#'                                       Other Federal Civil Service
#'
#'   Total Federal Employment =  Active Duty military +
#'                               DOD Civilian Direct Hires +
#'                               Other Federal Civil Service +
#'                               Coast Guard
#'
#'   Total US Employment = Total Federal Employment + (see above)
#'                         State and Local Gov't +
#'                         U.S. Private Sector Employment
#'
#'   Total US Labor Force = not sure? remove this and all unemployment. There are better sources.
#'
# # Libraries ---------------------------------------------------------------
library(tidyverse)
library(readxl)
library(stringr)
#' # How to Update this File -------------------------------------------------
#'
#'  #-#-#-#-#-#-#-#- Change this stuff #-#-#-#-#-#-#-#-#-#-#-#-
#'   -> Download Comptroller data to Raw folder (manually).
#'
#'  -> Identify current year
current.fy <- 2021
#'
#'
#'   -> Change year, verify file prefix (names generated automatically in tibble)
raw.filename <- "./Data/Raw/FY21 PB Green Book Chap 7.xlsx"
tab.name     <- "7-6"
#'
#'   ->Set working Directory to current year:
setwd("./DOD-Green-Book/FY2021")
#'   -> Verify Export name
export.filename <- "tbl_7.6_total.us.labor.force"
#'  #-#-#-#-#-#-#-#- This probably will NOT change #-#-#-#-#-#-#-#-#-#-#-#-
#' Includes table ranges and names
#'
#' Verify Tables #-#-#-#-#-#-#
#'
#'  Tables 7.6
my.colrange <- c( 7:13)  #<-- Current dataset
my.colnames <- c (    "FY",
"active.duty.military",
"dod.civilian.direct.hires",
"total.dod.employment",
"other.federal.civil.service",
"total.federal.civilian.employment",
"coast.guard",
"total.federal.employment",
"state.and.local.government",
"total.us.public.employment",
"us.private.sector.employment",
"total.us.employment",
"us.unemployment",
"total.us.labor.force")
#'
# Common Vars -------------------------------------------------------------
first.fy <- 1940
# export labelling
mylocation <- "./Data/Processed"
mydate <- paste('Updated', format(Sys.time(), format = "_%Y-%m-%d_%H%M") , sep = "")
my.export.filename <- sprintf("%s/%s_%s.csv", mylocation, export.filename, mydate)
# Import ------------------------------------------------------------------
df.1 <- read_excel(raw.filename,
sheet = tab.name,
skip= 5,
col_names=F)
# Reshaping ---------------------------------------------------------------
df.1 <- df.1[,-2]
df.1 <- df.1[grepl("^[0-9]{4}", df.1$...1) &
!grepl(".*(Base|OCO)", df.1$...1), ]
# renaming
df.1[ ,1 ]  <- as.character(first.fy:current.fy)
names(df.1) <- my.colnames
#remove columns with Total in name
df.1 <- df.1[, !grepl("total", names(df.1) ) ]
#remove untrustworthy us.unemployment
df.1 <- df.1[, !grepl("us.unemployment", names(df.1) ) ]
# NAs to zeros
df.1[is.na(df.1)] <- 0
df.2 <- gather(df.1, key = employment.category,
value = amount,
-FY) %>%
mutate(amount = amount *1e3)
final.df <- df.2
df.2
View(df.2)
final.df %>% spread(employment.category, amount)
final.df %>% spread(employment.category, amount) %>% View()
